# Cub 0.30 Public Alpha: Epics

**Goal:** Ship a public alpha where someone conversant with CLI coding tools can install cub, run through a workflow, and get far enough to provide useful feedback.

**Release type:** Quiet (friends & family), quality bar for useful feedback.

---

## Ownership Model

| Leader | Role | Best For |
|--------|------|----------|
| **Cub** | Code implementation, test writing, refactoring | Well-scoped tasks with clear acceptance criteria; changes to existing patterns |
| **Claude** | Research, analysis, doc writing, spike exploration, complex multi-file orchestration | Exploratory work, cross-cutting concerns, documentation, design decisions |
| **Marc** | Final decisions, human testing, UX judgment, external validation | Taste calls, real-world validation, stakeholder-facing work, final sign-off |

---

## Epic Ordering

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  PHASE 1: FOUNDATION                                                        │
│  ───────────────────                                                        │
│  E1: Default Backend Flip (JSON)                                            │
│  E2: Documentation Audit & Fixes                                            │
│  E3: CLI Polish & Consistency                                               │
│                                                                             │
├─────────────────────────────────────────────────────────────────────────────┤
│  PHASE 2: RELIABILITY                                                       │
│  ────────────────────                                                       │
│  E4: Core Loop Hardening                                                    │
│  E5: Circuit Breaker Spike                                                  │
│  E6: Symbiotic Workflow Spike                                               │
│                                                                             │
├─────────────────────────────────────────────────────────────────────────────┤
│  PHASE 3: VALIDATION                                                        │
│  ───────────────────                                                        │
│  E7: Human Testing Campaign                                                 │
│  E8: External Project Validation                                            │
│                                                                             │
├─────────────────────────────────────────────────────────────────────────────┤
│  PHASE 4: RELEASE                                                           │
│  ───────────────────                                                        │
│  E9: Release Packaging                                                      │
│  E10: Launch Content                                                        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Phase 1: Foundation

### E1: Default Backend Flip (JSON)

**Summary:** Change default task backend from beads to JSON for simpler alpha onboarding.

**Leader:** Cub (code changes) + Claude (doc updates)

**Acceptance Criteria:**
- [ ] `cub init` creates JSON backend by default (not beads)
- [ ] `cub init --backend beads` still works for opt-in
- [ ] README updated to reflect JSON as default
- [ ] Quick Start guide uses JSON backend
- [ ] Existing beads users see clear migration path in docs
- [ ] `cub doctor` reports backend type correctly

**Tasks:**
1. Update default in config/init logic
2. Update `cub init` templates
3. Update README Quick Start section
4. Add "Using Beads Backend" doc section
5. Test both backends work after change

**Estimated effort:** Small (1-2 hours code, 1 hour docs)

**Dependencies:** None

---

### E2: Documentation Audit & Fixes

**Summary:** Ensure README and docs accurately reflect current commands and capabilities.

**Leader:** Claude (audit + writing) + Marc (review)

**Acceptance Criteria:**
- [ ] Every command in `cub --help` is documented in README
- [ ] No references to deprecated commands (`cub prep`, old flags)
- [ ] Quick Start produces working output when followed exactly
- [ ] Security/permissions warning prominent in README intro
- [ ] Experimental features marked clearly (`[EXPERIMENTAL]`)
- [ ] Alpha status disclaimer at top of README
- [ ] CONTRIBUTING.md matches current architecture

**Tasks:**
1. Run `cub --help` and compare against README
2. Search for and remove `cub prep` references
3. Walk through Quick Start end-to-end, fix any gaps
4. Add alpha disclaimer banner to README
5. Add security warning section
6. Mark sandbox/toolsmith as experimental
7. Review CONTRIBUTING.md against current code structure

**Estimated effort:** Medium (3-4 hours)

**Dependencies:** E1 (backend flip affects Quick Start)

---

### E3: CLI Polish & Consistency

**Summary:** Audit CLI for consistent UX, helpful errors, and intuitive behavior.

**Leader:** Claude (audit) + Cub (implementation) + Marc (UX review)

**Acceptance Criteria:**
- [ ] All commands have helpful `--help` text (not just auto-generated)
- [ ] Error messages include actionable suggestions
- [ ] Exit codes are consistent (0=success, 1=error, 2=user error)
- [ ] `--debug` and `--verbose` work consistently across commands
- [ ] No harness available → clear error with setup instructions
- [ ] Git not initialized → clear error with suggestion
- [ ] `cub docs` command exists (opens docs in browser)
- [ ] `Development Status :: 3 - Alpha` classifier in pyproject.toml

**Tasks:**
1. Audit all command help text, improve where needed
2. Audit error handling, add suggestions to common errors
3. Standardize exit codes
4. Implement `cub docs` command
5. Add alpha classifier to pyproject.toml
6. Test error scenarios (no harness, no git, etc.)

**Estimated effort:** Medium (4-6 hours)

**Dependencies:** None (can parallel with E1, E2)

---

## Phase 2: Reliability

### E4: Core Loop Hardening

**Summary:** Ensure `cub run` is rock-solid: no crashes, clean exits, reliable state.

**Leader:** Cub (testing + fixes) + Marc (manual testing)

**Acceptance Criteria:**
- [ ] `cub run --once` completes without crash on happy path
- [ ] `cub run` (multi-task) completes or exits cleanly at budget
- [ ] Ctrl+C during run exits cleanly, no data corruption
- [ ] Ctrl+C during plan exits cleanly
- [ ] Budget exhaustion stops run with clear message
- [ ] Iteration limit stops run with clear message
- [ ] Task failure is handled gracefully (logged, continues or stops per config)
- [ ] Artifacts created even on failure/interrupt

**Tasks:**
1. Write/expand integration tests for run loop
2. Test signal handling (SIGINT, SIGTERM)
3. Test budget exhaustion scenarios
4. Test iteration limit scenarios
5. Test task failure handling
6. Verify artifact creation on all exit paths
7. Fix any issues found

**Estimated effort:** Medium-Large (6-8 hours)

**Dependencies:** E1 (test with JSON backend)

---

### E5: Circuit Breaker Spike

**Summary:** Explore and potentially implement stagnation detection to prevent wasted iterations.

**Leader:** Claude (design + spike) + Cub (implementation if proceeding)

**Acceptance Criteria (Spike):**
- [ ] Document current run loop state tracking
- [ ] Define stagnation signals (same files modified, same errors, no progress)
- [ ] Prototype detection logic
- [ ] Decision: include in 0.30 or defer to 0.31

**Acceptance Criteria (If Implementing):**
- [ ] Circuit breaker trips after N iterations with no task completion
- [ ] Circuit breaker trips on repeated same-file modifications
- [ ] Clear message when circuit trips
- [ ] Configurable thresholds in cub.toml
- [ ] Can be disabled with `--no-circuit-breaker`

**Tasks (Spike):**
1. Review current run loop and state tracking code
2. Document what signals are available
3. Design detection heuristics
4. Prototype in isolated branch
5. Make go/no-go decision for 0.30

**Tasks (If Implementing):**
6. Implement detection logic
7. Add configuration options
8. Add CLI flag
9. Write tests
10. Update docs

**Estimated effort:** Spike (2-3 hours), Implementation (4-6 hours)

**Dependencies:** E4 (understand run loop first)

---

### E6: Symbiotic Workflow Spike

**Summary:** Explore how cub-enabled projects work alongside direct harness use (Claude Code, etc.).

**Leader:** Claude (research + design) + Marc (workflow validation)

**Acceptance Criteria (Spike):**
- [ ] Document current state: what happens when user runs Claude Code directly?
- [ ] Identify integration points (git hooks, CLAUDE.md, session detection)
- [ ] Propose minimal alpha approach (even if just documentation)
- [ ] Decision: any code changes for 0.30 or defer?

**Possible Approaches to Evaluate:**
1. **Git-based detection:** Watch for non-cub commits, prompt to associate
2. **CLAUDE.md integration:** Cub writes context that direct sessions pick up
3. **Post-hoc reconciliation:** `cub reconcile` reviews recent commits
4. **Documentation only:** Explain the mental model, no code changes

**Tasks:**
1. Test: run Claude Code directly in cub-enabled project, what happens?
2. Review CLAUDE.md and how harnesses use it
3. Review git hooks system for integration opportunities
4. Document findings and recommend approach
5. If simple win exists, implement for alpha

**Estimated effort:** Spike (2-3 hours), Implementation TBD

**Dependencies:** None (can parallel)

---

## Phase 3: Validation

### E7: Human Testing Campaign

**Summary:** Systematically test all commands and flows per the testing plan.

**Leader:** Marc (primary tester) + Claude (issue triage)

**Acceptance Criteria:**
- [ ] All Installation & Setup tests pass
- [ ] All Task Management tests pass
- [ ] All Plan Pipeline tests pass
- [ ] All Run Loop tests pass
- [ ] At least one harness integration test passes
- [ ] Git integration tests pass
- [ ] Artifact creation tests pass
- [ ] All critical failures have GitHub issues

**Test Categories (from testing plan):**
1. Installation & Setup (8 tests)
2. Task Management / JSON Backend (8 tests)
3. Plan Pipeline (6 tests)
4. Run Loop / Core (10 tests)
5. Harness Integration (5 tests)
6. Git Integration (6 tests)
7. Artifacts & Observability (5 tests)
8. Hooks System (5 tests)

**Tasks:**
1. Execute Installation tests, document results
2. Execute Task Management tests, document results
3. Execute Plan Pipeline tests, document results
4. Execute Run Loop tests, document results
5. Execute remaining test categories
6. Create GitHub issues for failures
7. Triage: alpha-blocker vs can-defer

**Estimated effort:** Large (8-12 hours spread across multiple sessions)

**Dependencies:** E1-E4 complete

---

### E8: External Project Validation

**Summary:** Validate cub works on real projects beyond cub itself.

**Leader:** Marc (project selection + testing) + Claude (support)

**Acceptance Criteria:**
- [ ] Successfully init cub on an external Python project
- [ ] Successfully run at least one task on external project
- [ ] Document any friction or failures
- [ ] Successfully init cub on a non-Python project (JS/Go)
- [ ] Document language-agnostic limitations if any

**Candidate Projects:**
- Python: httpx, rich, typer, or similar well-maintained OSS
- JavaScript: small utility library
- Greenfield: create something from scratch with cub

**Tasks:**
1. Select 2-3 candidate projects
2. Clone and run `cub init`
3. Create a simple task (fix typo, add docstring, etc.)
4. Run `cub run --once`
5. Document results, friction points
6. Repeat for non-Python project
7. Fix critical issues or document known limitations

**Estimated effort:** Medium (4-6 hours)

**Dependencies:** E4, E7 (core should be stable first)

---

## Phase 4: Release

### E9: Release Packaging

**Summary:** Package and publish 0.30.0a1 to TestPyPI, then PyPI.

**Leader:** Cub (packaging) + Marc (validation)

**Acceptance Criteria:**
- [ ] Version bumped to 0.30.0a1
- [ ] Package builds locally without errors
- [ ] Package installs from wheel correctly
- [ ] Upload to TestPyPI succeeds
- [ ] Install from TestPyPI works on fresh machine
- [ ] Upload to PyPI succeeds
- [ ] Install from PyPI works: `pip install cub` or `pipx install cub`
- [ ] GitHub release created with release notes

**Tasks:**
1. Bump version in pyproject.toml
2. Build package locally (`python -m build`)
3. Test install from wheel
4. Upload to TestPyPI
5. Test install from TestPyPI (fresh venv)
6. Fix any issues
7. Upload to PyPI
8. Test install from PyPI
9. Create GitHub release with notes
10. Tag release in git

**Estimated effort:** Small-Medium (2-4 hours)

**Dependencies:** E7 complete, no alpha-blocker issues

---

### E10: Launch Content

**Summary:** Create minimal content for quiet alpha launch.

**Leader:** Claude (drafts) + Marc (editing + publishing)

**Acceptance Criteria:**
- [ ] README has compelling value prop in first paragraph
- [ ] GitHub release notes explain what's new and what to expect
- [ ] "Why I Built Cub" blog post draft exists (can polish later)
- [ ] Demo script exists for recording a walkthrough video
- [ ] Twitter/X thread draft ready for launch

**Tasks:**
1. Rewrite README intro with product thesis language
2. Write GitHub release notes (changelog + positioning)
3. Draft "Why I Built Cub" post (draw from rationale doc)
4. Write demo script (Quick Start walkthrough)
5. Draft Twitter thread (5-7 tweets)
6. Marc reviews and edits all content
7. Publish release notes with release
8. Decide: publish blog post now or hold for beta?

**Estimated effort:** Medium (4-6 hours writing, 2 hours editing)

**Dependencies:** E9 (release exists to link to)

---

## Summary: Epic Ownership

| Epic | Primary Leader | Support | Marc Required For |
|------|----------------|---------|-------------------|
| E1: Backend Flip | Cub | Claude (docs) | Review |
| E2: Doc Audit | Claude | - | Review, Quick Start validation |
| E3: CLI Polish | Claude + Cub | - | UX review |
| E4: Loop Hardening | Cub | Marc (testing) | Manual testing |
| E5: Circuit Breaker | Claude | Cub (if implementing) | Go/no-go decision |
| E6: Symbiotic Spike | Claude | - | Workflow validation, decision |
| E7: Human Testing | Marc | Claude (triage) | Primary executor |
| E8: External Validation | Marc | Claude | Primary executor |
| E9: Release Packaging | Cub | Marc (validation) | Final validation |
| E10: Launch Content | Claude | Marc (editing) | Final editing, publish decisions |

---

## Rough Timeline (Suggested)

| Phase | Epics | Duration |
|-------|-------|----------|
| **Phase 1** | E1, E2, E3 | 2-3 days (can parallel) |
| **Phase 2** | E4, E5, E6 | 3-4 days |
| **Phase 3** | E7, E8 | 3-4 days |
| **Phase 4** | E9, E10 | 1-2 days |
| **Buffer** | Bug fixes, surprises | 2 days |
| **Total** | | ~2 weeks |

---

## Open Questions

1. **Claude Tasks integration:** Spike before or after 0.30?
   - Current recommendation: After 0.30 (focus on core)

2. **Circuit breaker scope:** Include in 0.30 if spike looks good?
   - Depends on spike results

3. **Symbiotic workflow scope:** Any code changes for 0.30?
   - Depends on spike—likely documentation-only for alpha

4. **Demo video:** Record for alpha or wait for beta?
   - Recommendation: Script now, record for beta

---

## Definition of Done (0.30 Alpha)

The release is ready when:

1. ✅ All Phase 1 epics complete
2. ✅ All Phase 2 epics complete (spikes decided, core hardened)
3. ✅ E7 tests pass (no alpha-blockers)
4. ✅ E8 validates on at least one external project
5. ✅ E9 package published to PyPI
6. ✅ E10 README and release notes published
7. ✅ Marc has personally completed Quick Start on fresh machine
