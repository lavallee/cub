{"id": "cub-b1a", "title": "bare-cub #1: Core Run Extraction", "status": "open", "priority": "P0", "issue_type": "epic", "description": "Extract ~2500 lines of business logic from `cli/run.py` into a new `core/run/` package. This is the highest-risk, highest-impact phase — it establishes the pattern that every subsequent phase follows. All existing tests must continue passing after each extraction step.", "assignee": null, "labels": ["phase-1", "core", "refactor", "risk:high"], "dependsOn": [], "blocks": [], "parent": null, "created_at": "2026-01-28T17:54:44.407838", "updated_at": "2026-01-28T17:54:44.407842", "closed_at": null, "acceptanceCriteria": [], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 0}
{"id": "cub-b1b", "title": "bare-cub #2: Rich Boundary Cleanup", "status": "open", "priority": "P1", "issue_type": "epic", "description": "Remove all Rich imports from `cub.core` modules. Core returns structured data; CLI renders it. This establishes the architectural rule that enables non-CLI interfaces.", "assignee": null, "labels": ["phase-2", "core", "refactor", "cleanup"], "dependsOn": [], "blocks": [], "parent": null, "created_at": "2026-01-28T17:54:44.407983", "updated_at": "2026-01-28T17:54:44.407984", "closed_at": null, "acceptanceCriteria": [], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1c", "title": "bare-cub #3: Service Layer", "status": "open", "priority": "P1", "issue_type": "epic", "description": "Introduce `cub.core.services` as the public API surface. Services are thin orchestrators that compose domain operations. CLI modules are refactored to call services.", "assignee": null, "labels": ["phase-3", "core", "architecture"], "dependsOn": [], "blocks": [], "parent": null, "created_at": "2026-01-28T17:54:44.408044", "updated_at": "2026-01-28T17:54:44.408045", "closed_at": null, "acceptanceCriteria": [], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1d", "title": "bare-cub #4: Suggestion Engine", "status": "open", "priority": "P1", "issue_type": "epic", "description": "Build the smart recommendation system that analyzes project state and produces ranked, opinionated suggestions for what to do next.", "assignee": null, "labels": ["phase-4", "core", "feature"], "dependsOn": [], "blocks": [], "parent": null, "created_at": "2026-01-28T17:54:44.408089", "updated_at": "2026-01-28T17:54:44.408089", "closed_at": null, "acceptanceCriteria": [], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1e", "title": "bare-cub #5: Bare Cub Command", "status": "open", "priority": "P0", "issue_type": "epic", "description": "Implement the default command handler — the user-facing deliverable. When someone types `cub` with no subcommand, it launches the default harness with an opinionated welcome.", "assignee": null, "labels": ["phase-5", "cli", "feature"], "dependsOn": [], "blocks": [], "parent": null, "created_at": "2026-01-28T17:54:44.408186", "updated_at": "2026-01-28T17:54:44.408187", "closed_at": null, "acceptanceCriteria": [], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 0}
{"id": "cub-b1f", "title": "bare-cub #6: Skill Discovery & Documentation", "status": "open", "priority": "P2", "issue_type": "epic", "description": "Make cub capabilities discoverable from within a harness session and document the new architecture.", "assignee": null, "labels": ["phase-6", "docs", "feature"], "dependsOn": [], "blocks": [], "parent": null, "created_at": "2026-01-28T17:54:44.408236", "updated_at": "2026-01-28T17:54:44.408236", "closed_at": null, "acceptanceCriteria": [], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-b1a.1", "title": "Create core/run package with prompt builder extraction", "status": "open", "priority": "P0", "issue_type": "task", "description": "The prompt builder (system prompt generation, task context injection, AGENT.md reading) is the most self-contained piece of `cli/run.py` and the safest to extract first. It establishes the `core/run/` package structure.\n\n**Implementation Steps:**\n1. Create `src/cub/core/run/__init__.py` package\n2. Create `src/cub/core/run/prompt_builder.py` — extract `generate_system_prompt()`, `_build_task_context()`, `_read_agent_md()`, and related functions from `cli/run.py`\n3. Define `PromptConfig` and `TaskPrompt` data models for inputs/outputs\n4. Update `cli/run.py` to import from `core/run/prompt_builder` instead of using local functions\n5. Ensure all existing run tests pass unchanged\n6. Add unit tests for prompt builder in isolation\n\n**Files:** src/cub/core/run/__init__.py, src/cub/core/run/prompt_builder.py, src/cub/cli/run.py, tests/test_run_prompt_builder.py", "assignee": null, "labels": ["phase-1", "core", "refactor", "model:opus", "complexity:high", "blocking"], "dependsOn": [], "blocks": ["cub-b1a.2", "cub-b1a.3", "cub-b1a.4", "cub-b1a.5"], "parent": "cub-b1a", "created_at": "2026-01-28T17:54:46.169146", "updated_at": "2026-01-28T17:54:46.169149", "closed_at": null, "acceptanceCriteria": ["`core/run/prompt_builder.py` exists with all prompt generation logic", "`cli/run.py` calls prompt builder from core, no local prompt logic remains", "`pytest tests/` passes with no regressions", "`mypy src/cub` passes clean", "No Rich imports in `core/run/`"], "notes": "", "complexity_label": "high", "model_label": "opus", "is_ready": true, "priority_numeric": 0}
{"id": "cub-b1a.2", "title": "Extract budget tracking to core/run/budget.py", "status": "open", "priority": "P0", "issue_type": "task", "description": "Budget tracking (token counting, cost accounting, limit enforcement) is business logic embedded in the run loop. It needs to be accessible to any interface that runs tasks.\n\n**Implementation Steps:**\n1. Create `src/cub/core/run/budget.py` with `BudgetManager` class\n2. Extract token tracking, cost accumulation, and limit checking from `cli/run.py`\n3. Define `BudgetConfig` (limits) and `BudgetState` (current usage) models\n4. Add `check_limit()` method that returns whether to continue or stop\n5. Update `cli/run.py` to use `BudgetManager` instead of inline tracking\n6. Write tests for budget limit enforcement\n\n**Files:** src/cub/core/run/budget.py, src/cub/cli/run.py, tests/test_run_budget.py", "assignee": null, "labels": ["phase-1", "core", "refactor", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1a", "created_at": "2026-01-28T17:54:46.169250", "updated_at": "2026-01-28T17:54:46.169251", "closed_at": null, "acceptanceCriteria": ["`BudgetManager` handles all token/cost tracking", "Budget limits trigger clean stops with clear reasons", "`cli/run.py` has no inline budget math", "Tests cover: under budget, at budget, over budget, no budget set"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 0}
{"id": "cub-b1a.3", "title": "Extract loop state machine to core/run/loop.py", "status": "open", "priority": "P0", "issue_type": "task", "description": "The run loop state machine (pick task → execute → record → next) is the core of cub. Extracting it cleanly is the hardest part of this phase — it touches task selection, harness invocation, result recording, and error handling.\n\n**Implementation Steps:**\n1. Create `src/cub/core/run/loop.py` with `RunLoop` class\n2. Define `RunConfig` model (all loop configuration: once, epic, harness, etc.)\n3. Define `RunEvent` enum/model for loop events (task_start, task_end, budget_update, error, complete)\n4. Implement `execute()` as a generator that yields `RunEvent` objects\n5. Move task selection, harness invocation coordination, and result recording into `RunLoop`\n6. Keep signal handling and Rich rendering in `cli/run.py`\n7. `cli/run.py` becomes: parse args → create `RunConfig` → iterate `RunLoop.execute()` → render events\n\n**Files:** src/cub/core/run/loop.py, src/cub/core/run/models.py, src/cub/cli/run.py, tests/test_run_loop.py", "assignee": null, "labels": ["phase-1", "core", "refactor", "model:opus", "complexity:high", "risk:high"], "dependsOn": [], "blocks": [], "parent": "cub-b1a", "created_at": "2026-01-28T17:54:46.169288", "updated_at": "2026-01-28T17:54:46.169289", "closed_at": null, "acceptanceCriteria": ["`RunLoop.execute()` yields `RunEvent` stream, no print/console output", "`cli/run.py` reduced to <500 lines (arg parsing + event rendering)", "`cub run --once` works end-to-end through the new architecture", "`cub run` (multi-task) works end-to-end", "All existing run tests pass", "`mypy` passes clean"], "notes": "", "complexity_label": "high", "model_label": "opus", "is_ready": true, "priority_numeric": 0}
{"id": "cub-b1a.4", "title": "Extract interrupt handling to core/run/interrupt.py", "status": "open", "priority": "P1", "issue_type": "task", "description": "Signal handling (SIGINT/SIGTERM) for clean shutdown needs to work regardless of which interface is driving the run loop. The interrupt handler should coordinate with the loop state machine.\n\n**Implementation Steps:**\n1. Create `src/cub/core/run/interrupt.py` with `InterruptHandler` class\n2. Extract signal registration and `_interrupted` flag logic from `cli/run.py`\n3. Implement cooperative interruption: handler sets flag, loop checks flag between tasks\n4. Add `on_interrupt` callback for cleanup (artifact finalization, ledger entry)\n5. Update `RunLoop` to check interrupt state between iterations\n\n**Files:** src/cub/core/run/interrupt.py, src/cub/core/run/loop.py, src/cub/cli/run.py, tests/test_run_interrupt.py", "assignee": null, "labels": ["phase-1", "core", "refactor", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1a", "created_at": "2026-01-28T17:54:46.169329", "updated_at": "2026-01-28T17:54:46.169329", "closed_at": null, "acceptanceCriteria": ["`InterruptHandler` manages SIGINT/SIGTERM registration", "Interrupts cause clean shutdown between tasks (not mid-task)", "Artifacts and ledger entries are finalized on interrupt", "Works when called from CLI or programmatically"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1a.5", "title": "Extract git operations to core/run/git_ops.py", "status": "open", "priority": "P1", "issue_type": "task", "description": "Branch creation, commit tracking, and other git operations during `cub run` are business logic that should be accessible from any interface.\n\n**Implementation Steps:**\n1. Create `src/cub/core/run/git_ops.py` with run-specific git functions\n2. Extract `_create_branch_from_base()`, `_get_gh_issue_title()`, `_get_epic_title()` from `cli/run.py`\n3. Define clear interfaces: `create_run_branch(config) -> str`, `get_epic_context(epic_id) -> EpicContext`\n4. Update `RunLoop` to call git_ops functions instead of inline logic\n5. Write tests with mocked git operations\n\n**Files:** src/cub/core/run/git_ops.py, src/cub/cli/run.py, tests/test_run_git_ops.py", "assignee": null, "labels": ["phase-1", "core", "refactor", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1a", "created_at": "2026-01-28T17:54:46.169369", "updated_at": "2026-01-28T17:54:46.169369", "closed_at": null, "acceptanceCriteria": ["All git operations during run extracted to `core/run/git_ops.py`", "No git subprocess calls remain in `cli/run.py`", "Branch naming convention preserved", "Tests cover branch creation, epic title resolution"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1b.1", "title": "Move review reporter rendering to CLI layer", "status": "open", "priority": "P1", "issue_type": "task", "description": "`core/review/reporter.py` is the heaviest Rich violator — it's ~90% Rich rendering. The data models already exist in `core/review/models.py`. We need to split data preparation from rendering.\n\n**Implementation Steps:**\n1. Audit `core/review/reporter.py` to identify data preparation vs rendering\n2. Keep any data transformation logic in core; move to `core/review/formatter.py` if needed (returns structured data)\n3. Create `cli/review/display.py` with all Rich rendering (Panel, Table, Text)\n4. Update `cli/review.py` to call display functions instead of core reporter\n5. Remove Rich imports from `core/review/reporter.py` (or delete if fully moved)\n6. Update tests to verify data output, not rendered output\n\n**Files:** src/cub/core/review/reporter.py, src/cub/cli/review/display.py, src/cub/cli/review.py", "assignee": null, "labels": ["phase-2", "core", "cleanup", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": ["cub-b1b.5"], "parent": "cub-b1b", "created_at": "2026-01-28T17:54:46.169408", "updated_at": "2026-01-28T17:54:46.169409", "closed_at": null, "acceptanceCriteria": ["Zero Rich imports in `core/review/`", "`cli/review/display.py` handles all review rendering", "`cub review` command output unchanged from user's perspective", "Tests pass"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1b.2", "title": "Remove Rich from core/pr/service.py and core/worktree/parallel.py", "status": "open", "priority": "P1", "issue_type": "task", "description": "Both modules use Rich Console for progress/status output. They should emit events or return data, letting the CLI layer handle display.\n\n**Implementation Steps:**\n1. In `core/pr/service.py`: replace `Console` usage with return values or Python logging\n2. In `core/worktree/parallel.py`: replace progress output with callback/event pattern\n3. Define callback protocols: `on_worker_start(task_id)`, `on_worker_complete(task_id, result)`\n4. Update `cli/pr.py` and `cli/worktree.py` to provide Rich-based callbacks\n5. Verify all PR and worktree commands work unchanged\n\n**Files:** src/cub/core/pr/service.py, src/cub/core/worktree/parallel.py, src/cub/cli/pr.py, src/cub/cli/worktree.py", "assignee": null, "labels": ["phase-2", "core", "cleanup", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": ["cub-b1b.5"], "parent": "cub-b1b", "created_at": "2026-01-28T17:54:46.169430", "updated_at": "2026-01-28T17:54:46.169430", "closed_at": null, "acceptanceCriteria": ["Zero Rich imports in `core/pr/` and `core/worktree/`", "PR and worktree commands produce identical output", "Core modules use callbacks or return data for progress"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1b.3", "title": "Move bash_delegate to CLI layer", "status": "open", "priority": "P1", "issue_type": "task", "description": "`core/bash_delegate.py` imports Rich Console and calls `sys.exit()`. It's purely a CLI concern — delegating commands to the bash version of cub.\n\n**Implementation Steps:**\n1. Move `core/bash_delegate.py` to `cli/delegated/runner.py`\n2. Update imports in `cli/delegated.py` and `cli/__init__.py`\n3. Remove `core/bash_delegate.py`\n4. Verify delegated commands (prep, branch, etc.) still work\n\n**Files:** src/cub/core/bash_delegate.py, src/cub/cli/delegated/runner.py, src/cub/cli/delegated.py", "assignee": null, "labels": ["phase-2", "core", "cleanup", "model:sonnet", "complexity:low"], "dependsOn": [], "blocks": [], "parent": "cub-b1b", "created_at": "2026-01-28T17:54:46.169447", "updated_at": "2026-01-28T17:54:46.169448", "closed_at": null, "acceptanceCriteria": ["`core/bash_delegate.py` no longer exists", "Delegated commands work unchanged", "No Rich or sys.exit in any `core/` module"], "notes": "", "complexity_label": "low", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1b.4", "title": "Replace Rich logging in core/harness/hooks.py", "status": "open", "priority": "P1", "issue_type": "task", "description": "`core/harness/hooks.py` uses Rich for logging. It should use Python's standard `logging` module — hooks run in subprocess contexts where Rich may not be appropriate.\n\n**Implementation Steps:**\n1. Replace `from rich.console import Console` with `import logging`\n2. Replace `console.print()` calls with `logger.info()`, `logger.debug()`, etc.\n3. Configure logging format in hook entry point\n4. Verify hook forensics still work correctly\n\n**Files:** src/cub/core/harness/hooks.py", "assignee": null, "labels": ["phase-2", "core", "cleanup", "model:haiku", "complexity:low"], "dependsOn": [], "blocks": [], "parent": "cub-b1b", "created_at": "2026-01-28T17:54:46.169467", "updated_at": "2026-01-28T17:54:46.169467", "closed_at": null, "acceptanceCriteria": ["Zero Rich imports in `core/harness/hooks.py`", "Hook logging works in subprocess contexts", "Forensics JSONL output unchanged"], "notes": "", "complexity_label": "low", "model_label": "haiku", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1b.5", "title": "Verify zero Rich imports in core and add CI gate", "status": "open", "priority": "P1", "issue_type": "task", "description": "Final verification that the boundary is clean, plus a CI check to prevent regression.\n\n**Implementation Steps:**\n1. Run `grep -r \"from rich\" src/cub/core/` and verify zero results\n2. Run `grep -r \"import rich\" src/cub/core/` and verify zero results\n3. Add a test that programmatically checks no Rich imports in core\n4. Verify `mypy src/cub` passes clean\n\n**Files:** tests/test_architecture.py", "assignee": null, "labels": ["phase-2", "core", "cleanup", "model:haiku", "complexity:low"], "dependsOn": [], "blocks": [], "parent": "cub-b1b", "created_at": "2026-01-28T17:54:46.169492", "updated_at": "2026-01-28T17:54:46.169492", "closed_at": null, "acceptanceCriteria": ["`grep -r \"from rich\\|import rich\" src/cub/core/` returns nothing", "Automated test enforces the boundary", "All commands work unchanged from user's perspective"], "notes": "", "complexity_label": "low", "model_label": "haiku", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1c.1", "title": "Create service layer foundation and RunService", "status": "open", "priority": "P1", "issue_type": "task", "description": "RunService wraps the newly-extracted `core/run/` package, providing the clean API that CLI and future interfaces call. This establishes the service layer pattern.\n\n**Implementation Steps:**\n1. Create `src/cub/core/services/__init__.py` package\n2. Create `src/cub/core/services/run.py` with `RunService` class\n3. `RunService.from_config(config)` factory method\n4. `RunService.execute(run_config) -> Iterator[RunEvent]` delegates to `core/run/loop.py`\n5. `RunService.run_once(task_id) -> RunResult` convenience method\n6. Refactor `cli/run.py` to use `RunService` instead of calling `core/run/` directly\n7. Write service-level integration tests\n\n**Files:** src/cub/core/services/__init__.py, src/cub/core/services/run.py, src/cub/cli/run.py, tests/test_service_run.py", "assignee": null, "labels": ["phase-3", "core", "architecture", "model:opus", "complexity:high", "blocking"], "dependsOn": [], "blocks": ["cub-b1c.2", "cub-b1c.3", "cub-b1c.4"], "parent": "cub-b1c", "created_at": "2026-01-28T17:54:46.169509", "updated_at": "2026-01-28T17:54:46.169510", "closed_at": null, "acceptanceCriteria": ["`RunService` provides the complete API for task execution", "`cli/run.py` only calls `RunService`, not domain modules directly", "Service is stateless — configuration passed in, no globals", "Tests verify service orchestration"], "notes": "", "complexity_label": "high", "model_label": "opus", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1c.2", "title": "Create StatusService and LedgerService", "status": "open", "priority": "P1", "issue_type": "task", "description": "StatusService aggregates project state from multiple sources. LedgerService wraps ledger reader/writer. Both are needed by the suggestion engine.\n\n**Implementation Steps:**\n1. Create `src/cub/core/services/status.py` with `StatusService`\n2. `summary() -> ProjectStats` — aggregate from tasks, ledger, git\n3. `progress(epic_id) -> EpicProgress` — epic-level progress\n4. Create `src/cub/core/services/ledger.py` with `LedgerService`\n5. `query(filters) -> list[LedgerEntry]`, `recent(n) -> list[LedgerEntry]`, `stats(period) -> LedgerStats`\n6. Define `ProjectStats`, `EpicProgress`, `LedgerStats` models\n7. Refactor `cli/status.py` and `cli/ledger.py` to use services\n\n**Files:** src/cub/core/services/status.py, src/cub/core/services/ledger.py, src/cub/core/services/models.py, src/cub/cli/status.py, src/cub/cli/ledger.py", "assignee": null, "labels": ["phase-3", "core", "architecture", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1c", "created_at": "2026-01-28T17:54:46.169529", "updated_at": "2026-01-28T17:54:46.169529", "closed_at": null, "acceptanceCriteria": ["`StatusService.summary()` returns structured project stats", "`LedgerService` wraps all ledger operations", "`cub status` and `cub ledger` commands work via services", "Models are Pydantic, serializable"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1c.3", "title": "Create LaunchService for environment detection and harness launch", "status": "open", "priority": "P1", "issue_type": "task", "description": "LaunchService handles the core logic for bare `cub`: detect environment, determine if nested, launch harness with context. This is the service that `cli/default.py` will call.\n\n**Implementation Steps:**\n1. Create `src/cub/core/launch/__init__.py` package\n2. Create `src/cub/core/launch/detector.py` with `detect_environment() -> EnvironmentInfo`\n3. Check `CUB_SESSION_ACTIVE`, `CLAUDE_CODE`, `CLAUDE_PROJECT_DIR` env vars\n4. Create `src/cub/core/launch/launcher.py` with `launch_harness(config, context)`\n5. Implement harness binary resolution, flag assembly, `exec` call\n6. Create `src/cub/core/launch/models.py` with `EnvironmentInfo`, `LaunchConfig`\n7. Create `src/cub/core/services/launch.py` with `LaunchService` wrapper\n8. Write tests with mocked environment variables\n\n**Files:** src/cub/core/launch/detector.py, src/cub/core/launch/launcher.py, src/cub/core/launch/models.py, src/cub/core/services/launch.py, tests/test_launch.py", "assignee": null, "labels": ["phase-3", "core", "architecture", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1c", "created_at": "2026-01-28T17:54:46.169545", "updated_at": "2026-01-28T17:54:46.169545", "closed_at": null, "acceptanceCriteria": ["`detect_environment()` correctly identifies terminal, harness, and nested contexts", "`launch_harness()` assembles correct `claude` CLI invocation", "`--resume` and `--continue` flags pass through correctly", "`CUB_SESSION_ACTIVE` and `CUB_SESSION_ID` set in child environment", "Tests cover all three environment contexts"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1c.4", "title": "Enhance TaskService with ready(), stale_epics(), and claims", "status": "open", "priority": "P1", "issue_type": "task", "description": "TaskService already exists but needs additional methods for the suggestion engine and welcome message. `ready()` and `stale_epics()` are key data sources for suggestions.\n\n**Implementation Steps:**\n1. Add `ready() -> list[Task]` to TaskService — tasks with no blockers, ordered by priority\n2. Add `stale_epics() -> list[Epic]` — epics where all child tasks are closed but epic is open\n3. Add `claim(task_id, session_id) -> Task` — mark task as in-progress for a session\n4. Add `close(task_id, reason) -> Task` — close task with reason\n5. Ensure methods work with both beads and JSONL backends\n6. Write tests for each method with both backends\n\n**Files:** src/cub/core/tasks/service.py, tests/test_task_service.py", "assignee": null, "labels": ["phase-3", "core", "architecture", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1c", "created_at": "2026-01-28T17:54:46.169561", "updated_at": "2026-01-28T17:54:46.169561", "closed_at": null, "acceptanceCriteria": ["`TaskService.ready()` returns correctly filtered and ordered tasks", "`TaskService.stale_epics()` detects epics ready to close", "Works with beads and JSONL backends", "Tests cover edge cases (no tasks, all blocked, mixed states)"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1d.1", "title": "Create suggestion models and data sources", "status": "open", "priority": "P1", "issue_type": "task", "description": "Define the data models for suggestions and implement the four data source adapters (tasks, git, ledger, milestones) that feed the ranking engine.\n\n**Implementation Steps:**\n1. Create `src/cub/core/suggestions/__init__.py` package\n2. Create `src/cub/core/suggestions/models.py` with `Suggestion`, `ProjectSnapshot`, `SuggestionCategory` enum\n3. Create `src/cub/core/suggestions/sources.py` with source protocol and implementations:\n4. Each source implements `get_suggestions() -> list[Suggestion]`\n5. Write tests with fixture data mirroring current cub project state\n\n**Files:** src/cub/core/suggestions/models.py, src/cub/core/suggestions/sources.py, tests/test_suggestions_sources.py", "assignee": null, "labels": ["phase-4", "core", "feature", "model:sonnet", "complexity:medium", "blocking"], "dependsOn": [], "blocks": ["cub-b1d.2", "cub-b1d.3"], "parent": "cub-b1d", "created_at": "2026-01-28T17:54:46.169582", "updated_at": "2026-01-28T17:54:46.169582", "closed_at": null, "acceptanceCriteria": ["All four sources produce relevant suggestions from real project data", "`TaskSource` detects the 9 stale epics in current project", "`GitSource` detects unpushed work and stale branches", "`MilestoneSource` infers 0.30 alpha target from sketches/CHANGELOG", "Models are Pydantic, serializable"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1d.2", "title": "Implement ranking algorithm and engine", "status": "open", "priority": "P1", "issue_type": "task", "description": "The ranking algorithm scores and orders suggestions from all sources. The engine composes sources, applies ranking, and provides the public API.\n\n**Implementation Steps:**\n1. Create `src/cub/core/suggestions/ranking.py` with `rank_suggestions(suggestions) -> list[Suggestion]`\n2. Implement scoring: `base_priority × urgency_multiplier × recency_decay`\n3. Create `src/cub/core/suggestions/engine.py` with `SuggestionEngine` class\n4. `get_suggestions(limit) -> list[Suggestion]` — ranked list\n5. `get_welcome() -> WelcomeMessage` — stats + top suggestions + skills\n6. `get_next_action() -> Suggestion` — single best recommendation\n7. Write tests with deterministic fixture data to verify ranking order\n\n**Files:** src/cub/core/suggestions/ranking.py, src/cub/core/suggestions/engine.py, tests/test_suggestions_engine.py", "assignee": null, "labels": ["phase-4", "core", "feature", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1d", "created_at": "2026-01-28T17:54:46.169599", "updated_at": "2026-01-28T17:54:46.169599", "closed_at": null, "acceptanceCriteria": ["Stale epic closure ranks above low-priority ready tasks", "P0 tasks rank above P2 tasks", "Milestone blockers rank high when release target detected", "`get_welcome()` produces a complete `WelcomeMessage` with stats", "Ranking is deterministic for same input"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1d.3", "title": "Wire SuggestionEngine into services and dogfood", "status": "open", "priority": "P1", "issue_type": "task", "description": "Connect the engine to real project data via services and validate it produces useful suggestions for the cub project itself.\n\n**Implementation Steps:**\n1. Create `src/cub/core/services/suggestions.py` as the service wrapper\n2. Wire `SuggestionEngine` to use `TaskService`, `LedgerService`, `StatusService`\n3. Add a CLI command for testing: `cub suggest` (or add to `cub status`)\n4. Run against the current cub project and verify suggestions are sensible\n5. Iterate on ranking weights based on dogfooding results\n6. Document the suggestion categories and their use cases\n\n**Files:** src/cub/core/services/suggestions.py, src/cub/cli/suggest.py, tests/test_suggestions_integration.py", "assignee": null, "labels": ["phase-4", "core", "feature", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1d", "created_at": "2026-01-28T17:54:46.169615", "updated_at": "2026-01-28T17:54:46.169615", "closed_at": null, "acceptanceCriteria": ["`cub suggest` (or equivalent) produces useful output for cub project", "Suggestions include stale epics, ready tasks, and milestone awareness", "Output is human-readable and actionable", "Engine handles empty projects gracefully (new project with no tasks)"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1e.1", "title": "Implement bare cub default command handler", "status": "open", "priority": "P0", "issue_type": "task", "description": "This is the primary user-facing deliverable. Bare `cub` detects the environment, generates a welcome message with suggestions, and either launches the harness (terminal) or shows inline status (nested/harness).\n\n**Implementation Steps:**\n1. Create `src/cub/cli/default.py` with the default command function\n2. Wire into `cli/__init__.py`: replace `no_args_is_help=True` with callback that invokes default\n3. Accept `--resume` and `--continue` flags\n4. Call `LaunchService.detect_environment()` to determine context\n5. If nested/harness: call `SuggestionEngine.get_welcome()`, render with Rich, exit\n6. If terminal: generate welcome, resolve harness, launch with `LaunchService.launch_harness()`\n7. Set `CUB_SESSION_ACTIVE=1` and `CUB_SESSION_ID` in launched harness environment\n8. Handle edge cases: no harness available, no project initialized, help flag\n\n**Files:** src/cub/cli/default.py, src/cub/cli/__init__.py, tests/test_default_command.py", "assignee": null, "labels": ["phase-5", "cli", "feature", "model:opus", "complexity:high", "blocking"], "dependsOn": [], "blocks": ["cub-b1e.2", "cub-b1e.3"], "parent": "cub-b1e", "created_at": "2026-01-28T17:54:46.169633", "updated_at": "2026-01-28T17:54:46.169633", "closed_at": null, "acceptanceCriteria": ["`cub` (no args) launches Claude Code with welcome context", "`cub --resume` passes `--resume` to Claude Code", "`cub --continue` passes `--continue` to Claude Code", "`cub` inside Claude Code shows inline status + suggestions (no nesting)", "`cub` with no harness available shows helpful error", "`cub --help` still works (shows help, not default action)", "Welcome message includes project stats and top suggestion"], "notes": "", "complexity_label": "high", "model_label": "opus", "is_ready": true, "priority_numeric": 0}
{"id": "cub-b1e.2", "title": "Design and implement welcome message format", "status": "open", "priority": "P1", "issue_type": "task", "description": "The welcome message is the first thing users see. It needs to be concise, opinionated, and immediately useful. It renders differently in terminal (Rich formatting) vs inline (plain text for harness context).\n\n**Implementation Steps:**\n1. Create `src/cub/core/launch/welcome.py` with `generate_welcome(snapshot) -> WelcomeMessage`\n2. Design terminal format (Rich):\n3. Design harness context format (plain text for system prompt injection)\n4. Create Rich renderer in `cli/default.py` for terminal output\n5. Test with current cub project state\n\n**Files:** src/cub/core/launch/welcome.py, src/cub/cli/default.py, tests/test_welcome.py", "assignee": null, "labels": ["phase-5", "cli", "feature", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1e", "created_at": "2026-01-28T17:54:46.169652", "updated_at": "2026-01-28T17:54:46.169652", "closed_at": null, "acceptanceCriteria": ["Welcome message shows version, task counts, and last activity", "Top suggestion is opinionated with rationale and command", "Available skills listed for discoverability", "Terminal and harness formats both look good", "Handles empty project gracefully (no tasks, no history)"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1e.3", "title": "Integration testing and edge cases", "status": "open", "priority": "P1", "issue_type": "task", "description": "The bare cub command has many edge cases that need testing: no project, no harness, nested sessions, resume/continue, different backends.\n\n**Implementation Steps:**\n1. Write integration test: bare cub in fresh directory (no `.cub/`)\n2. Write integration test: bare cub with JSONL backend\n3. Write integration test: bare cub with beads backend\n4. Write integration test: bare cub with `CUB_SESSION_ACTIVE=1` set\n5. Write integration test: bare cub with `--resume`\n6. Write integration test: bare cub when no harness available\n7. Test that `cub --help` still shows help text\n8. Test that `cub <subcommand>` still routes to subcommands normally\n\n**Files:** tests/test_default_command_integration.py", "assignee": null, "labels": ["phase-5", "cli", "test", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1e", "created_at": "2026-01-28T17:54:46.169673", "updated_at": "2026-01-28T17:54:46.169674", "closed_at": null, "acceptanceCriteria": ["All integration tests pass", "No regressions in existing subcommand routing", "Edge cases produce helpful error messages, not crashes", "`--help` behavior preserved"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-b1f.1", "title": "Create /cub meta-skill for in-session discovery", "status": "open", "priority": "P2", "issue_type": "task", "description": "Users inside a harness session need to discover what cub skills are available. A `/cub` meta-skill lists available skills, common commands, and current project status.\n\n**Implementation Steps:**\n1. Create `.claude/commands/cub.md` as the meta-skill\n2. Include: list of available `/cub:*` skills with one-line descriptions\n3. Include: common `cub` CLI commands runnable via Bash (task ready, status, run)\n4. Include: brief explanation of modes (conversational, structured, supervised, autonomous)\n5. Include: dynamic project state (injected via template variables or by running `cub status`)\n\n**Files:** .claude/commands/cub.md", "assignee": null, "labels": ["phase-6", "docs", "feature", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1f", "created_at": "2026-01-28T17:54:46.169693", "updated_at": "2026-01-28T17:54:46.169693", "closed_at": null, "acceptanceCriteria": ["`/cub` skill exists and is invocable from Claude Code", "Lists all available `/cub:*` skills", "Lists common CLI commands", "Provides enough context for a user to navigate cub's capabilities"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 2}
{"id": "cub-b1f.2", "title": "Update CLAUDE.md with service architecture and skill reference", "status": "open", "priority": "P2", "issue_type": "task", "description": "CLAUDE.md needs to reflect the new core/interface architecture so that harness sessions (and agents) understand cub's structure. Also document available skills.\n\n**Implementation Steps:**\n1. Update CLAUDE.md architecture section to reflect service layer\n2. Add \"Available Skills\" section listing all `/cub:*` skills\n3. Add \"Cub Commands\" section with commonly-used CLI commands\n4. Update project structure diagram to show `core/services/`, `core/run/`, `core/suggestions/`, `core/launch/`\n5. Add note about bare `cub` behavior and nesting detection\n6. Remove any outdated references to old architecture\n\n**Files:** CLAUDE.md", "assignee": null, "labels": ["phase-6", "docs", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1f", "created_at": "2026-01-28T17:54:46.169709", "updated_at": "2026-01-28T17:54:46.169710", "closed_at": null, "acceptanceCriteria": ["CLAUDE.md reflects current service layer architecture", "Skills section lists all available skills with descriptions", "Project structure diagram is accurate", "A harness session loading CLAUDE.md gets accurate information"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 2}
{"id": "cub-b1f.3", "title": "End-to-end validation of full flow", "status": "open", "priority": "P1", "issue_type": "task", "description": "Final validation that the entire flow works: bare `cub` → harness → use skills → run tasks → exit. This is the acceptance test for the whole feature.\n\n**Implementation Steps:**\n1. Manual test: run `cub` from terminal, verify welcome + harness launch\n2. Manual test: inside harness, run `/cub` to see available skills\n3. Manual test: inside harness, run `/cub:spec` to start a spec\n4. Manual test: inside harness, run `cub task ready` to see tasks\n5. Manual test: inside harness, run `cub run --once` for foreground task\n6. Manual test: run `cub` inside the harness (verify nesting prevention)\n7. Document any issues found, create follow-up tasks if needed\n\n**Files:** (manual testing, no code changes expected)", "assignee": null, "labels": ["phase-6", "test", "model:sonnet", "complexity:medium"], "dependsOn": [], "blocks": [], "parent": "cub-b1f", "created_at": "2026-01-28T17:54:46.169724", "updated_at": "2026-01-28T17:54:46.169725", "closed_at": null, "acceptanceCriteria": ["Full flow works without crashes or confusing behavior", "Mode transitions feel natural", "Nesting prevention works correctly", "Any issues found are documented as follow-up tasks"], "notes": "", "complexity_label": "medium", "model_label": "sonnet", "is_ready": true, "priority_numeric": 1}
{"id": "cub-n6x", "title": "2026-01-28-assorted Bug Fixes", "status": "open", "priority": "P2", "issue_type": "epic", "description": "Punchlist tasks from: 2026-01-28-assorted-bugs.md", "assignee": null, "labels": ["punchlist", "punchlist:2026-01-28-assorted-bugs"], "dependsOn": [], "blocks": [], "parent": null, "created_at": "2026-01-29T01:58:07.311189", "updated_at": "2026-01-29T01:58:07.311193", "closed_at": null, "acceptanceCriteria": [], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.1", "title": "Fix label order comparison in backend divergence checks", "status": "open", "priority": "P2", "issue_type": "task", "description": "The backend divergence detection compares task labels as ordered lists, causing false positives when labels appear in different orders between the beads backend (alphabetically sorted) and in-memory state. Since labels are semantically unordered, comparisons should use set equality instead, eliminating spurious warnings while maintaining detection of real label divergences.\n\n**Implementation Steps:**\n1. Locate backend divergence checks in `close_task()` and `get_task()` operations within the tasks backend implementation\n2. Convert label list comparisons to set comparisons (e.g., `set(a.labels) == set(b.labels)`)\n3. Update any helper functions or comparison logic that currently treat labels as ordered sequences\n4. Add test cases verifying set-based comparison with various label orderings (different permutations of the same labels)\n5. Run tests to confirm false positives are eliminated while real divergences are still detected", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.211916", "updated_at": "2026-01-29T01:58:08.211921", "closed_at": null, "acceptanceCriteria": ["Backend divergence checks compare labels as sets, not lists", "False positives from label reordering are eliminated", "Real divergences (actual label additions/removals) are still detected", "No warnings logged when only label order differs", "Tests verify set-based comparison with various label orderings", "All existing tests pass with changes"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.2", "title": "Fix monitor command to work with beads backend", "status": "open", "priority": "P2", "issue_type": "task", "description": "The `cub monitor` command fails with \"No active session found\" error because it was designed for a session-based architecture that has been replaced by beads-based task management. The monitor command needs to be updated to work with the current task backend system, displaying real-time progress on beads tasks instead of looking for legacy session state. This is a critical UX feature for autonomous execution visibility.\n\n**Implementation Steps:**\n1. Investigate current session/task state storage in codebase (check how `cub run` tracks execution, beads backend integration)\n2. Review `cub monitor` implementation to understand what \"active session\" lookup is attempting\n3. Determine appropriate data source for live task progress (beads task status, run loop state, or execution ledger)\n4. Refactor monitor to query beads backend and display real-time task progress\n5. Update help text and error messages to reflect beads-based monitoring\n6. Test monitor command during `cub run` execution to verify real-time updates\n7. Add fallback behavior when no tasks are running (clear message instead of error)", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212055", "updated_at": "2026-01-29T01:58:08.212056", "closed_at": null, "acceptanceCriteria": ["`cub monitor` executes without \"No active session found\" error", "Command displays live task progress when `cub run` is executing", "Shows appropriate status message when no tasks are running", "Works with beads backend task management system", "Help text accurately describes monitoring beads tasks", "Works both standalone and during active `cub run` sessions"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.3", "title": "Add post-command guidance messages to key cub workflows", "status": "open", "priority": "P2", "issue_type": "task", "description": "Users new to cub lack clear direction after running commands, leaving them uncertain about next steps. Contextual guidance messages will improve onboarding and reduce friction by providing actionable next steps with concrete examples. This is a UX improvement focused on making cub more intuitive for new users.\n\n**Implementation Steps:**\n1. Create a guidance module (`cub/core/guidance.py`) with a `GuidanceProvider` class to generate contextual next-step messages based on command type and result\n2. Add guidance output to `cub init` command - display suggested next steps (create capture, run interview, start task) after successful initialization\n3. Add guidance output to `cub capture` command - suggest next steps (review capture, start interview, organize into spec) after capture creation\n4. Add guidance output to `cub spec` command - guide to next phase (detailed requirements, link to epic, schedule planning) after spec creation\n5. Implement `--quiet` flag support across these commands to suppress guidance messages when desired\n6. Format guidance using Rich tables/panels for readability and consistency\n7. Add tests for guidance module and verify all commands respect quiet flag", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212115", "updated_at": "2026-01-29T01:58:08.212115", "closed_at": null, "acceptanceCriteria": ["`cub init` displays 3-5 actionable next steps with copyable command examples after initialization", "`cub capture` displays 3-5 actionable next steps after successful capture creation", "`cub spec` displays 3-5 actionable next steps after successful spec creation", "All guidance messages respect `--quiet` flag and suppress output when enabled", "Guidance uses Rich formatting (tables or panels) for consistent, readable output", "Command examples in guidance are accurate and directly copyable", "All existing command behavior remains unchanged (guidance is additive only)", "Unit tests cover guidance message generation for each command type"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.4", "title": "Configure git upstream on feature branch creation", "status": "open", "priority": "P2", "issue_type": "task", "description": "When build-plan creates a feature branch, it doesn't set upstream tracking, causing `git push` to fail with \"fatal: The current branch has no upstream branch.\" Users must manually run `git push --set-upstream origin <branch>` before subsequent pushes work. This friction breaks the autonomous workflow where agents should be able to push changes without manual git intervention.\n\n**Implementation Steps:**\n1. Locate the feature branch creation logic in build-plan (likely in `cub.core.launch` or a related module that handles git operations)\n2. After creating the local branch, immediately configure upstream tracking by either:", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212201", "updated_at": "2026-01-29T01:58:08.212202", "closed_at": null, "acceptanceCriteria": ["Feature branches created by build-plan have upstream tracking configured", "`git push` works on new branches without `--set-upstream` flag", "Works for both new local branches and existing branches being pushed for first time", "Tests confirm upstream tracking is set and push operations succeed", "Documentation updated in CLAUDE.md"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.5", "title": "Check completed steps before launching architect in plan run", "status": "open", "priority": "P2", "issue_type": "task", "description": "The `cub plan run` command currently assumes architect should launch automatically upon exit, but this breaks workflows where earlier steps are incomplete or partially completed. Users need visibility into which prep pipeline steps (triage, architect, plan, bootstrap) have already been done so they can decide whether to continue, re-run a step, or skip ahead. The system should detect artifacts from previous runs and guide users through the pipeline intelligently rather than blindly advancing.\n\n**Implementation Steps:**\n1. Create a step detection function that checks for completion artifacts (triage markdown files, architect outputs, plan.jsonl, beads state) in the project\n2. Display a summary table showing which prep steps are completed, in-progress, or incomplete when exiting plan run\n3. Prompt the user with options: continue to next incomplete step, re-run a specific step, or exit\n4. Route the selected action back to the appropriate plan subcommand (orient, architect, plan, bootstrap)\n5. Handle edge cases: partial architect completion, missing intermediate steps, corrupted artifacts", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212245", "updated_at": "2026-01-29T01:58:08.212246", "closed_at": null, "acceptanceCriteria": ["Detects completion status of all four prep steps via artifact inspection", "Displays step summary before prompting for next action", "Offers user choice to continue, re-run, or exit (not forced into architect)", "Does not launch architect if earlier steps are incomplete", "Gracefully handles partial completion and corrupted artifacts"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.6", "title": "Add build failure detection and retry logic to cub pr", "status": "open", "priority": "P2", "issue_type": "task", "description": "The `cub pr` command currently creates pull requests but has no visibility into CI check status or automated recovery from transient failures. This means flaky tests, rate limits, and temporary service issues require manual intervention, interrupting autonomous workflows. Adding automated failure detection and retry logic would enable self-healing PR workflows that handle common transient failures without manual handoff.\n\n**Implementation Steps:**\n1. Create `cub.core.services.pr_monitor` module to implement check polling and failure detection via `gh pr checks`\n2. Add retry configuration model to `cub.core.config` with timeout duration and max retry count parameters\n3. Extend `LaunchService` to support background PR monitoring while harness is active\n4. Implement check state machine: poll → detect failure → wait → retry → repeat or succeed\n5. Add `--retry-timeout` and `--no-retry` flags to `cub pr` command in `cub.cli.pr`\n6. Integrate check monitoring into session hooks to log retry history to session forensics\n7. Add check status and retry attempts to `cub.core.ledger` models for session ledger recording\n8. Write integration tests for check detection, retry triggering, and rate limit handling", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212294", "updated_at": "2026-01-29T01:58:08.212295", "closed_at": null, "acceptanceCriteria": ["`cub pr` detects PR check failures via `gh pr checks` polling", "Automatic retry timer (default 10 minutes, configurable) activates when failures detected", "`--retry-timeout` flag accepts duration strings (e.g., `5m`, `30s`)", "`--no-retry` flag disables automatic retry behavior for all check types", "Failed checks are re-triggered via `gh pr checks --rerun` or equivalent", "Session forensics (`.cub/ledger/forensics/{session_id}.jsonl`) logs all check statuses and retry attempts with timestamps", "Max retries (default 3) prevents infinite loop; stops retrying after limit reached", "Handles `gh` API rate limiting and network errors gracefully with exponential backoff", "Works with both draft PRs (`--draft`) and regular PRs"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.7", "title": "Ensure plan.json is created at pipeline start", "status": "open", "priority": "P2", "issue_type": "task", "description": "plan.json is currently written during the orient stage rather than when the plan context is first created. If orient fails before calling ctx.save_plan(), there's no plan.json file to recover from. This reduces fault tolerance and prevents resumption in cases where early stage failures occur. Creating plan.json immediately after context initialization ensures a persistent checkpoint exists from the start.\n\n**Implementation Steps:**\n1. Locate PipelineConfig.run() and identify where PlanContext is created or loaded\n2. Add ctx.save_plan() call immediately after plan context initialization, before any stage runs\n3. Verify orient stage's existing ctx.save_plan() call at line 484 doesn't duplicate writes\n4. Run full test suite to ensure pipeline behavior remains unchanged\n5. Verify plan.json exists at project root before any stage execution begins", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212336", "updated_at": "2026-01-29T01:58:08.212336", "closed_at": null, "acceptanceCriteria": ["plan.json is created immediately after plan context initialization", "plan.json exists before orient stage executes", "All existing tests pass with no behavioral changes", "Plan data is recoverable/resumable even if orient fails early"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.8", "title": "Remove deprecated cub:triage and cub:plan skill commands", "status": "open", "priority": "P2", "issue_type": "task", "description": "The cub:triage and cub:plan skill commands are no longer needed and create maintenance overhead. These commands were part of an earlier planning pipeline that has been superseded by other tooling. Removing them will reduce code complexity, eliminate dead skill registrations, and prevent confusion about available planning commands. This is a straightforward cleanup task with no backward compatibility concerns.\n\n**Implementation Steps:**\n1. Search the codebase for all references to `cub:triage` and `cub:plan` (skill definitions, command registrations, templates)\n2. Remove skill command definitions for `cub:triage` and `cub:plan` from skill/command template files\n3. Remove any `.claude/commands` configuration entries that register these skills\n4. Remove skill routing and registration code that supports these commands\n5. Search for any remaining references (comments, documentation, imports) and clean them up\n6. Verify no broken references remain by grepping for \"cub:triage\" and \"cub:plan\" across the codebase", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212370", "updated_at": "2026-01-29T01:58:08.212371", "closed_at": null, "acceptanceCriteria": ["`cub:triage` no longer appears in any templates, configuration files, or code", "`cub:plan` no longer appears in any templates, configuration files, or code", "All skill registration/routing code that handled these commands is removed", "Remaining skills and commands continue to function correctly (verify with `cub --help`)", "No broken imports or dangling references to removed skill definitions", "Git status shows only the intended removals (no accidental changes)"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.9", "title": "Add harness and model info to task headline", "status": "open", "priority": "P2", "issue_type": "task", "description": "The task headline box currently displays only basic task metadata (ID, title, priority, type, iteration), but doesn't show the runtime configuration (harness backend, model) that the iteration will use. This makes it difficult for developers to understand which AI backend and model will be executing their task, especially in contexts where multiple backends are available or when switching between different model configurations. Adding this information to the headline improves visibility into the execution environment and helps catch configuration mismatches early.\n\n**Implementation Steps:**\n1. Identify where the headline box is rendered during task iteration startup (in both `cub run` flow and direct session context)\n2. Extract harness backend and model information from the current run context or task configuration\n3. Modify the headline rendering logic to include harness backend and model as additional display fields\n4. Implement graceful fallback to omit fields when not configured (no \"None\" or empty values displayed)\n5. Test layout with various configuration combinations to ensure readability and prevent excessive line wrapping\n6. Verify the changes work in both `cub run` autonomous mode and direct harness session contexts\n7. Add or update tests to cover headline rendering with different harness/model configurations", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212407", "updated_at": "2026-01-29T01:58:08.212407", "closed_at": null, "acceptanceCriteria": ["Headline box displays harness backend name when available", "Headline box displays model name when available", "Other explicit configuration specs are included if applicable", "Layout remains readable without excessive line wrapping", "Unconfigured specs are omitted gracefully (no \"None\", \"N/A\", or blank values shown)", "Changes work in both `cub run` and direct session contexts", "Existing tests pass and new tests cover headline rendering scenarios"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.10", "title": "Add newlines between streamed harness messages", "status": "open", "priority": "P2", "issue_type": "task", "description": "When `cub run --stream` outputs AI harness messages, consecutive messages are concatenated without visual separation, making the output difficult to read and follow. Adding newlines between each streamed message improves readability and creates a cleaner user experience across all harness backends.\n\n**Implementation Steps:**\n1. Locate the stream message output handling in the run loop (likely in `cub.core.run` or `cub.cli.run`)\n2. Identify where harness messages are printed/streamed to stdout\n3. Add a newline character after each complete message is output\n4. Ensure the newline only appears between messages, not duplicated at message start/end\n5. Test with `cub run --stream` to verify output formatting with multiple consecutive messages\n6. Verify non-stream output remains unchanged and unaffected by the change\n7. Test with multiple harness backends (claude, codex, gemini) to ensure consistency", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212440", "updated_at": "2026-01-29T01:58:08.212440", "closed_at": null, "acceptanceCriteria": ["Each streamed message is followed by exactly one newline character", "Output is readable with clear visual separation between consecutive messages", "Non-stream output (`cub run` without `--stream`) is unaffected", "Works correctly with all harness backends (claude, codex, gemini, opencode)", "No duplicate blank lines or extra whitespace introduced", "Existing tests still pass and new behavior is tested"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
{"id": "cub-n6x.11", "title": "Add progress updates during punchlist item processing", "status": "open", "priority": "P2", "issue_type": "task", "description": "The punchlist processing command currently provides no feedback during the hydration phase, leaving users uncertain whether work is progressing or if the tool has hung. This is especially noticeable when processing larger punchlist files (10+ items) with API calls. Adding item-by-item progress updates will provide real-time visibility into processing status and improve the user experience without adding complexity.\n\n**Implementation Steps:**\n1. Locate the punchlist processing command and hydration loop (likely in `src/cub/cli/` or `src/cub/core/`)\n2. Identify where items are iterated during hydration and replace silent iteration with Rich progress tracking\n3. Extract item titles/summaries to display alongside progress indicator in format \"[N/TOTAL]\"\n4. Use Rich's Progress or live output utilities to stream updates without blocking\n5. Test with multiple punchlist sizes to ensure no significant latency is introduced\n6. Verify output integrates cleanly with existing Rich console patterns in cub", "assignee": null, "labels": ["punchlist"], "dependsOn": [], "blocks": [], "parent": "cub-n6x", "created_at": "2026-01-29T01:58:08.212476", "updated_at": "2026-01-29T01:58:08.212477", "closed_at": null, "acceptanceCriteria": ["Progress indicator displays \"[current/total]\" format for each item", "Item title or brief summary appears alongside progress update", "Updates appear incrementally as each item completes processing", "No measurable latency increase compared to current implementation", "Output uses Rich console consistent with other cub commands", "Works correctly with punchlist files of varying sizes (3-50+ items)"], "notes": "", "complexity_label": null, "model_label": null, "is_ready": true, "priority_numeric": 2}
